{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "02807_Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7sVQeTkLYI2b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "362px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "interpreter": {
      "hash": "c66c630706217e3a010f48b864026cc87c4c3bb876d794d9e6fd30ae5531d371"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02807: Project 1\n",
        " \n",
        "## Practical information\n",
        " \n",
        "* This project must be completed in groups of 3 students.\n",
        "    * The group must be registered on the course site on DTU Learn: My Course > Groups\n",
        "* This project must be handed in as a jupyter notebook to the course site on DTU Learn. \n",
        "    * Go to the Course Content > Assignments tab to upload your submission. \n",
        "* This project is due on Monday, November 1, 20:00.\n",
        "\n",
        "## Submission rules\n",
        "\n",
        "* Each group has to hand in *one* notebook (`.ipynb`) with their solutions, including a filled out Contribution table (see below).\n",
        "* Your solution must be written in Python.\n",
        "* For each question you should use the cells provided (\"`# your code goes here`\") for your solution\n",
        "    * It is allowed to add code cells within a question block, but consider if it's really necessary.\n",
        "* You should not remove the problem statements, and you should not modify the structure of the notebook.\n",
        "* Your notebook should be runnable and readable from top to bottom.\n",
        "    * Meaning that your code cells work when run in order (from top to bottom).\n",
        "    * Output of any cell depends only on itself and cells above it.\n",
        "* Your notebook should be submitted after having been run from top to bottom.\n",
        "    * This means outputs are interpretable without necessarily running your cells.\n",
        "    * The simplest way to achieve this is using the jupyter menu item Kernel > Restart & Run All just prior to submission. If any cell fails when you do this, your notebook is not ready for submission.\n",
        "* Failure to comply may make it impossible for us to evaluate your submission properly, which will likely negatively impact the points awarded.\n",
        "    \n",
        " \n",
        "## Colaboration policy\n",
        " \n",
        "* It is not allowed to collaborate on the exercises with students outside your group, except for discussing the text of the exercise with teachers and fellow students enrolled on the course in the same semester. \n",
        "* It is not allowed to exchange, hand-over or in any other way communicate solutions or parts of solutions to the exercises. \n",
        "* It is not allowed to use solutions from similar courses, or solutions found elsewhere."
      ],
      "metadata": {
        "id": "PlsPJUw7wCWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contribution table and grading\n",
        "\n",
        "* The total amount of points in the project is 110.\n",
        "* You have to indicate who has solved each part of each exercise in a **contribution table**. \n",
        "* The following is an example of a contributions table:\n",
        "\n",
        "|        | Exercise 1 | Exercise 2 | Exercise 3 | Exercise 4 |\n",
        "|--------|------------|------------|------------|------------|\n",
        "| **Part 1** | John       |    Mary        |     Ann       |   Mary, Ann         |\n",
        "| **Part 2** |     Mary       |    Mary        |   Ann         |    John, Ann        |\n",
        "| **Part 3** |     John, Mary, Ann       |      John, Ann      |   John         | **n.a.**      |\n",
        "| **Part 4** | **n.a.**       |  Ann          |     John, Mary       | **n.a.**       |\n",
        "| **Part 5** | **n.a.**     | John, Mary, Ann           | John       | **n.a.**       |\n",
        "\n",
        "* A group member can take credit for solving a part of an exercise only if they have contributed **substantially** to the solution. \n",
        "    * Simple contributions, such as correcting a small bug or double-checking the results of functions, are not sufficient for taking credit for a solution.\n",
        "    * Several group members can take credit for the same solution if they all have contributed substantially to it.\n",
        "* Each group member must contribute **at least 50 points**. \n",
        "    * If no name is provided for an exercise's part, **all group members** are considered contributors to it.\n",
        "* Group members should decide amongst themselves how to collaborate on the project to meet the above-mentioned constraints.  \n",
        "* Scores are individual. The score $\\text{score}(m)$ for a group member $m$ ranges from 0 to 10 and is calculated as follows: \n",
        "\n",
        "  * $\\text{individual-score}(m) = \\frac{\\text{total number of points for the parts correctly solved by }m}{\\text{total number of points for the parts contributed by }m}$\n",
        "\n",
        "  * $\\text{group-score} = \\frac{\\text{total number of points correctly solved by any group member}}{\\text{total number of points in the project}}$\n",
        "\n",
        "  * $\\text{score}(m) =  7.5 \\cdot \\text{individual-score}(m) + 2.5 \\cdot \\text{group-score}$\n",
        "\n",
        "* **Example**: in the contribution table above, suppose that all parts are solved correctly except for those of Exercise 4, which are both wrong. Then Ann's score is calculated as follows:\n",
        "\n",
        "  * $\\text{individual-score}(Ann) = \\frac{2.5+12.5+12.5+2.5+15+5}{2.5+12.5+12.5+2.5+15+5 + 10 + 10} = \\frac{50}{70} = 0.714$\n",
        "\n",
        "  * $\\text{group-score} = \\frac{90}{110} = 0.818$\n",
        "\n",
        "  * $\\text{score}(Ann) = 7.5\\cdot 0.714 + 2.5 \\cdot 0.818 = 7.4$\n"
      ],
      "metadata": {
        "id": "ZP30rwxHDQyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group declaration table \n",
        "\n",
        "This table must be filled before submission.\n",
        "\n"
      ],
      "metadata": {
        "id": "vklet8XdRGVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "d = {'Exercise 1' : [\"\", \"\", \"\", \"---\", \"---\"], \r\n",
        "     'Exercise 2' : [\"\", \"\", \"\", \"\", \"\"],\r\n",
        "     'Exercise 3' : [\"\", \"\", \"\", \"\", \"\"], \r\n",
        "     'Exercise 4' : [\"\", \"\", \"---\", \"---\", \"---\"],\r\n",
        "     } \r\n",
        "  \r\n",
        "ct = pd.DataFrame(d, index =['Part 1','Part 2','Part 3','Part 4','Part 5']) \r\n",
        "\r\n",
        "ct"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Exercise 1</th>\n",
              "      <th>Exercise 2</th>\n",
              "      <th>Exercise 3</th>\n",
              "      <th>Exercise 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Part 1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Part 2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Part 3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Part 4</th>\n",
              "      <td>---</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Part 5</th>\n",
              "      <td>---</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>---</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Exercise 1 Exercise 2 Exercise 3 Exercise 4\n",
              "Part 1                                            \n",
              "Part 2                                            \n",
              "Part 3                                         ---\n",
              "Part 4        ---                              ---\n",
              "Part 5        ---                              ---"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T15:03:19.791917Z",
          "start_time": "2021-09-27T15:03:19.764408Z"
        },
        "id": "chiXA3CzRSA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to the Datasets"
      ],
      "metadata": {
        "_uuid": "d7aa1b0ad6979877450f9cd89e1e37289b51cf6e",
        "id": "CF8tC7Z8CgbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![link text](https://ph-files.imgix.net/069dd825-cddf-4048-adde-8e81396c2c68?auto=format)\n",
        "\n",
        "\n",
        "You will be working with datasets obtained through the [The Movie Database (TMDb) API](https://developers.themoviedb.org/3/getting-started/introduction). The first dataset is part of the MovieLens Latest Full Dataset, comprising 26 million ratings on 45.000 movies from 27.000 users. Let's look at the features in this dataset.\n",
        "\n",
        "**Features**\n",
        "\n",
        "* **adult**: Indicates if the movie is X-Rated.\n",
        "* **belongs_to_collection**: A stringified dictionary with info on the movie series a particular film belongs to (e.g.: Lord of the Rings).\n",
        "* **budget**: The movie budget in dollars.\n",
        "* **genres**: A stringified list of dictionaries describing all genres associated with the movie.\n",
        "* **homepage**: The movie's official homepage.\n",
        "* **id**: An identifier for the movie.\n",
        "* **imdb_id**: IMDB's identifier for the movie.\n",
        "* **original_language**: The language in which the movie was shot.\n",
        "* **original_title**: The original title of the movie.\n",
        "* **overview**: A brief text about the movie.\n",
        "* **popularity**: A Popularity Score given by TMDb.\n",
        "* **poster_path**: The URL of the poster image.\n",
        "* **production_companies**: A stringified list of production companies involved with making of the movie.\n",
        "* **production_countries**: A stringified list of countries in which the movie was produced.\n",
        "* **release_date**: Release date of the movie in theaters.\n",
        "* **revenue**: The total revenue of the movie in dollars.\n",
        "* **runtime**: The runtime of the movie in minutes.\n",
        "* **spoken_languages**: A stringified list of languages spoken in the film.\n",
        "* **status**: The status of the movie (Released, To Be Released, etc.)\n",
        "* **tagline**: The movie's tagline.\n",
        "* **title**: The official title of the movie.\n",
        "* **video**: Indicates whether there is a video of the movie in TMDb.\n",
        "* **vote_average**: The average rating of the movie, on a 0-10 scale.\n",
        "* **vote_count**: The number of votes by users, as counted by TMDb."
      ],
      "metadata": {
        "id": "pO8N4lj29u9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "First, let's make sure to import Pandas and NumPy. "
      ],
      "metadata": {
        "_uuid": "6b418588e3f9139f74cb3a9546f5dca49729579b",
        "id": "2Clue5Z_Cgbc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T10:09:32.802462Z",
          "start_time": "2021-09-27T10:09:30.598648Z"
        },
        "id": "A0K3Aw3eAf2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Loading, preprocessing and cleaning the data (15 points)"
      ],
      "metadata": {
        "id": "PFlHk-e0BZME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the movie dataset from the following URL."
      ],
      "metadata": {
        "id": "mGJnqtQD1BOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "source": [
        "url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies_metadata.csv'"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T10:09:34.147572Z",
          "start_time": "2021-09-27T10:09:34.145160Z"
        },
        "id": "sQb46KRIAkOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Reading and preprocessing the data (10 pts)\n",
        "\n",
        "Pandas infers a data type for raw data from a `.csv`, defaulting to string type when no other `dtype` could be established. For example, the `genres` column in our dataset is read as a string with a *stringified* list of dictionaries as cell content. \n",
        "\n",
        "Some preprocessing steps are therefore needed, to convert the columns into their proper data types.\n",
        "\n",
        "Write a function `load_movies_data()` that reads the URL into a Pandas DataFrame and preprocesses its columns to ensure that:\n",
        "\n",
        "1. Data in the `release_date` column consists of Pandas `Timestamp` objects, except for missing values. For example, executing a code cell with `df.release_date[0]` should display the output `Timestamp('1995-10-30 00:00:00')`.\n",
        "\n",
        "2. Data in `belongs_to_collection` consists of dictionaries, except for missing values.\n",
        "\n",
        "3. Data in `genres`, `production_companies` and `production_countries` consists of lists of dictionaries, except for missing values. \n",
        "\n",
        "For example, executing a code cell with `df.genres[0]` should display the output \n",
        "```\n",
        "[{'id': 16, 'name': 'Animation'},\n",
        " {'id': 35, 'name': 'Comedy'},\n",
        " {'id': 10751, 'name': 'Family'}]\n",
        "```\n",
        "which is a list type, not a string. The elements of the list are dictionaries (executing `df.genres[0][0]['name']` returns `'Animation'`). \n",
        "\n",
        "**Hint**: for items 2 and 3, you should use `ast.literal_eval`.\n",
        "\n",
        "These conversions can be performed using Pandas' built-in functions and/or calling Pandas' `apply()` with appropriate arguments. Avoid explicit looping. You'll be asked below to time the loading and preprocessing step. "
      ],
      "metadata": {
        "id": "jQrm5PleClKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "source": [
        "import json\r\n",
        "# def load_movies_data(url):\r\n",
        "# df = pd.read_csv(url, dtype={\"release_date\": pd.to_datetime(df['release_date'], errors='coerce')})\r\n",
        "df = pd.read_csv(url)\r\n",
        "\r\n",
        "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\r\n",
        "df['belongs_to_collection'] = df['belongs_to_collection'].to_dict()\r\n",
        "print(df.dtypes)\r\n",
        "print(df.belongs_to_collection[0])\r\n",
        "that = df.belongs_to_collection[0]\r\n",
        "print(that['id'])\r\n",
        "# s = df['belongs_to_collection'].replace(\"{\", \"\")\r\n",
        "# finalstring = s.replace(\"}\", \"\")\r\n",
        "# list = finalstring.split(\",\")\r\n",
        "# dictionary = {}\r\n",
        "# for i in list:\r\n",
        "#     keyval = i.split(\":\")\r\n",
        "\r\n",
        "    # df['release_date'] = pd.to_datetime(df['release_date'], format='%Y/%m/%d')\r\n",
        "\r\n",
        "print(df.release_date[0])\r\n",
        "    # return df\r\n",
        "\r\n",
        "# data = load_movies_data(url)\r\n",
        "    # release_date should be timestamp\r\n",
        "    # belongs_to_collection consists of dictionaries\r\n",
        "    # genres, production_companies, and production_countries consist of lists of dictionaries"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adult                            object\n",
            "belongs_to_collection            object\n",
            "budget                           object\n",
            "genres                           object\n",
            "homepage                         object\n",
            "id                               object\n",
            "imdb_id                          object\n",
            "original_language                object\n",
            "original_title                   object\n",
            "overview                         object\n",
            "popularity                       object\n",
            "poster_path                      object\n",
            "production_companies             object\n",
            "production_countries             object\n",
            "release_date             datetime64[ns]\n",
            "revenue                         float64\n",
            "runtime                         float64\n",
            "spoken_languages                 object\n",
            "status                           object\n",
            "tagline                          object\n",
            "title                            object\n",
            "video                            object\n",
            "vote_average                    float64\n",
            "vote_count                      float64\n",
            "dtype: object\n",
            "{'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg', 'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31532/2675546008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbelongs_to_collection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbelongs_to_collection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# s = df['belongs_to_collection'].replace(\"{\", \"\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# finalstring = s.replace(\"}\", \"\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ],
      "metadata": {
        "id": "2mC5hjGXJTZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now call `load_movies_data()` and load the data into a DataFrame `df`."
      ],
      "metadata": {
        "id": "oZvSPPdzfScL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "4-eOSqlhD-8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the DataFrame. You should check that it looks correct."
      ],
      "metadata": {
        "id": "bnelY1bZzj-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "tP6zpeLxu4J-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Timing your function (2.5 pts)\n",
        "\n",
        "Time the performance of your function. To get the points for this part, the time reported below must not exceed 40 seconds."
      ],
      "metadata": {
        "id": "PuzjOV7ffbpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "load_time = %timeit -o -r 3 load_movies_data(url)\r\n",
        "print(\"Time (s):\", load_time.best)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_movies_data' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14472/588788111.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-o -r 3 load_movies_data(url)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time (s):\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2346\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2348\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2349\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'load_movies_data' is not defined"
          ]
        }
      ],
      "metadata": {
        "id": "aIYWL17bO2Ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Cleaning the data (2.5 pts)"
      ],
      "metadata": {
        "id": "7sVQeTkLYI2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter/drop all rows in `df` meeting any of these conditions:\n",
        "* The `adult` value is not `'False'`\n",
        "* The `vote_count` value is missing\n",
        "* The `vote_average` value is missing\n",
        "\n",
        "Do not loop over rows to perform these checks. Use Pandas' built-in functionality to do so. "
      ],
      "metadata": {
        "id": "6ydbZ-KFYlRX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qtb7AaaVY5nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Computing IMDb's ratings (35 points)"
      ],
      "metadata": {
        "id": "mT8jdILukiBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Top Rated 250 titles in IMDb are calculated using [a formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#calculatetop) that takes into account the number of votes that a title has received, the minimum votes required to be on the list, and the mean vote for all titles. The rating for a title is given as follows:\n",
        "\n",
        "$$ \\text{weighted rating } = \\left(\\frac{v}{v+m} \\cdot R\\right) + \\left(\\frac{m}{v+m} \\cdot C\\right)$$\n",
        "\n",
        "Where:\n",
        "\n",
        "$m$ = the minimum number of votes required to be listed in the Top Rated ranking. We'll let $m=1000$.\n",
        "\n",
        "$v$ = the number of votes received by the title (the title's **`vote_count`** value)\n",
        "\n",
        "$R$ = the average rating for the title (the title's **`vote_average`** value)\n",
        "\n",
        "$C$ = the mean vote across the whole list (the mean over the **`vote_average`** column)"
      ],
      "metadata": {
        "id": "84SE_eMzkyC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to compute the ratings for movies that could be listed in IMDb's Top Rated 250 ranking.  We want to do this as efficiently as possible. As a baseline for benchmarking, we'll use an approach that explicitly loops and indexes over the rows of the dataset and computes the weighted rating for the corresponding movie (if the movie has more than 1000 votes). "
      ],
      "metadata": {
        "id": "85J4HDO2rieA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "C = df['vote_average'].mean()\n",
        "m = 1000\n",
        "\n",
        "def weighted_rating(row):\n",
        "    if row['vote_count'] > m:\n",
        "        v = row['vote_count']\n",
        "        R = row['vote_average']\n",
        "        return (v/(v+m) * R) + (m/(v+m) * C)\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "def weighted_rating_loop(df):\n",
        "    rating_list = []\n",
        "    for i in range(len(df)):\n",
        "        rating = weighted_rating(df.iloc[i])\n",
        "        rating_list.append(rating)\n",
        "    df['imdb_rating'] = rating_list"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T10:27:52.905697Z",
          "start_time": "2021-09-27T10:27:52.800529Z"
        },
        "id": "MyYhLdBksTec"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "weighted_rating_loop(df)\n",
        "\n",
        "columns_to_show = ['id', 'original_title'] + \\\n",
        "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
        "df[columns_to_show].head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "JIsei1w4r9Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the average performance of this function:"
      ],
      "metadata": {
        "id": "JdlffrsJyHvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "basic_time = %timeit -r 3 -o weighted_rating_loop(df)\n",
        "print(\"Best time:\", basic_time.best)"
      ],
      "outputs": [],
      "metadata": {
        "id": "su__dMpZyX5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the remaining parts of the exercise, you are going to be asked to come up with alternative ways to compute the ratings, using various methodologies. Let's create a score board to keep track of performance. Here's a description of the rows:\n",
        "\n",
        "*   **Best single run time (s)**:  The best time used by your solution, in seconds.\n",
        "*   **Marginal performance improvement**: The time improvement of your current solution over its immediately preceding solution. Given by: $\\frac{\\text{best single run time (s) of previous solution}}{\\text{best single run time (s) of current solution}}$\n",
        "*   **Performance improvement over basic looping**:  The time improvement over our baseline solution. Given by: $\\frac{\\text{best single run time (s) of weighted_rating_loop}}{\\text{best single run time (s) of current solution}}$\n",
        "*   **Best single run time (s, teacher)**: The time of a solution provided by the teacher. \n",
        "*   **Marginal performance improvement (teacher)**: The time improvement of the teacher's solution over its immediately preceding solution. \n",
        "*   **Performance improvement over basic looping (teacher)**:  The teacher's solution improvement over the baseline solution.\n",
        "\n"
      ],
      "metadata": {
        "id": "HPjyKJ2zzPoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "timing_data = {\n",
        "    'Best single run time (s)': [basic_time.best, np.nan, np.nan, np.nan,np.nan],\n",
        "    'Marginal performance improvement': [np.nan,np.nan, np.nan, np.nan,np.nan],\n",
        "    'Performance improvement over basic looping': np.nan,\n",
        "    'Best single run time (s, teacher)': [9.37, 3.87, 0.562, 0.0054, 0.00084],\n",
        "    'Marginal performance improvement (teacher)': [np.nan, 'x2.42', 'x6.88', 'x103.8', 'x6.45'],\n",
        "    'Performance improvement over basic looping (teacher)': [np.nan, 'x2.42', 'x16.69', 'x1732.17','x11172.98']\n",
        "}\n",
        "\n",
        "indices = ['Basic looping', 'Iterrows looping', 'apply()', 'Pandas vectorisation', 'NumPy vectorisation']\n",
        "timings = pd.DataFrame(timing_data, index=indices)\n",
        "timings"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T11:03:14.455052Z",
          "start_time": "2021-09-27T11:03:14.442251Z"
        },
        "id": "fV-xfrs53NBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The grading for the following parts works as follows.**\n",
        "\n",
        "Let $m$ be the marginal performance improvement for the teacher's solution over basic looping, and let $m'$ be the marginal performance improvement for your solution over `basic_time`. If a part gives $n$ points, then you will get the $n$ points if $m' \\geq 0.4 m$, and 0 points otherwise.\n",
        "\n",
        "You don't get extra points for performing faster than the teacher's solution. But this is of course possible and you should feel free to optimise away as much as you want!"
      ],
      "metadata": {
        "id": "ZfD0eUlHgz3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Looping with `iterrows` (2.5 pts)"
      ],
      "metadata": {
        "id": "JkiLI2QT7oNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function `weighted_rating_iterrows(df)` that computes the ratings by looping over rows with the built-in iterator `iterrows`, and stores the results in a new column of the DataFrame called called `imdb_rating_iter`."
      ],
      "metadata": {
        "id": "bmZIqPIf743q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "m4dTxRfW6Gc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function and make sure that it works as intended."
      ],
      "metadata": {
        "id": "rsvOtN6y8Ycg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "weighted_rating_iterrows(df)\n",
        "\n",
        "pd.testing.assert_series_equal(\n",
        "    df.imdb_rating, df.imdb_rating_iter, check_names=False\n",
        ")\n",
        "\n",
        "columns_to_show = ['id', 'original_title'] + \\\n",
        "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
        "df[columns_to_show].head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "sLKzzVP86bza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time the performance of the function."
      ],
      "metadata": {
        "id": "AC-m0iR48jM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "iterrows_time = %timeit -r 3 -o weighted_rating_iterrows(df)\n",
        "print(\"Best time:\", iterrows_time.best)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9y3BWusJ8y70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ],
      "metadata": {
        "id": "HexMOOCB82e_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "_SQRS_gdJCbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Using `apply()`. (5 pts)"
      ],
      "metadata": {
        "id": "7-FhuhB99em4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function `weighted_rating_apply(df)` that computes the ratings using Pandas' `apply()` function, and stores the results in a new column of the DataFrame called `imdb_rating_apply`."
      ],
      "metadata": {
        "id": "iZ294FYn9qhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gk3SdbQs8ghG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function and make sure that it works as intended."
      ],
      "metadata": {
        "id": "jBgP1e1uCMlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "weighted_rating_apply(df)\n",
        "\n",
        "pd.testing.assert_series_equal(\n",
        "    df.imdb_rating, df.imdb_rating_apply, check_names=False\n",
        ")\n",
        "\n",
        "columns_to_show = ['id', 'original_title'] + \\\n",
        "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
        "df[columns_to_show].head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "wUaYXC_RCMlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time the performance of the function."
      ],
      "metadata": {
        "id": "C9jjZI14CMlO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "apply_time = %timeit -r 3 -o weighted_rating_apply(df)\n",
        "print(\"Best time:\", apply_time.best)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jqggBfTMCMlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ],
      "metadata": {
        "id": "9DzMnzf4CMlS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "-4RSuVOYV0JZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Vectorised solution with Pandas (12.5 pts)"
      ],
      "metadata": {
        "id": "TZHPgFMsED_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find a vectorised solution using Pandas. You have to define a function `weighted_rating_pandas(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_pandas`. Use Pandas operations only: don't transform your data into NumPy arrays."
      ],
      "metadata": {
        "id": "CI7zQxGNGZnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "WqIXsMGFGZnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function and make sure it works as intended."
      ],
      "metadata": {
        "id": "qKVGubslGZna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "weighted_rating_pandas(df)\n",
        "\n",
        "pd.testing.assert_series_equal(\n",
        "    df.imdb_rating, df.imdb_rating_pandas, check_names=False\n",
        ")\n",
        "\n",
        "columns_to_show = ['id', 'original_title'] + \\\n",
        "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
        "df[columns_to_show].head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "yXf4KAj1GZna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time the performance of the function."
      ],
      "metadata": {
        "id": "scNFR7X8GZnc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pandas_time = %timeit -r 3 -o weighted_rating_pandas(df)\n",
        "print(\"Best time:\", pandas_time.best)"
      ],
      "outputs": [],
      "metadata": {
        "id": "TbhwZZ0mGZnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ],
      "metadata": {
        "id": "Xsqz0kUJGZnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "SxCI0nUXV3Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to reflect on your solution. Do the following: \n",
        " \n",
        "* Explain in words what your function does and why it is a vectorised solution. In particular, break down each step involving ufuncs, broadcasting and other vectorized calls. \n",
        "    * If your explanation has major errors, we will substract points for this part.\n",
        " \n",
        "* Display profiler output and give an analysis of what you see."
      ],
      "metadata": {
        "id": "HvwaE7pIjzEa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "bQHB_JqeV52E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your explanation goes here*"
      ],
      "metadata": {
        "id": "DngbQA2eV770"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Vectorised solution with NumPy (12.5 pts)"
      ],
      "metadata": {
        "id": "QLwJEzATEKwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find a vectorised solution that uses NumPy to speed up the calculations. You have to define a function `weighted_rating_numpy(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_numpy`."
      ],
      "metadata": {
        "id": "GrAZ4OI2EPk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "9sJlkDYAzQr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the function and make sure it works as intended."
      ],
      "metadata": {
        "id": "n2pAc_GEEudy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "weighted_rating_numpy(df)\n",
        "\n",
        "pd.testing.assert_series_equal(\n",
        "    df.imdb_rating, df.imdb_rating_numpy, check_names=False\n",
        ")\n",
        "\n",
        "columns_to_show = ['id', 'original_title'] + \\\n",
        "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
        "df[columns_to_show].head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "IALbcsKO2RNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time the best performance of the function."
      ],
      "metadata": {
        "id": "r0ebRPwiFAfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numpy_time = %timeit -r 3 -o weighted_rating_numpy(df)\n",
        "print(\"Best time:\", numpy_time.best)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eWe52oAQ6l8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
      ],
      "metadata": {
        "id": "TB7tkhUDFAfr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8MBiqnvushL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to reflect on your solution. Do the following: \n",
        " \n",
        "* Explain in words what your function does and why it is a vectorised solution. In particular, break down each step involving ufuncs, broadcasting and other vectorized calls. \n",
        "    * If your explanation has major errors, we will substract points for this part.\n",
        "    * If applicable, you may refer back to the explanation you gave for `weighted_rating_pandas`.\n",
        " \n",
        "* Display profiler output and give an analysis of what you see.\n",
        "    * Contrast your findings with those from `weighted_rating_pandas`."
      ],
      "metadata": {
        "id": "8RSyEDTvA-QQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "FV8aYhv5WEqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your explanation goes here*"
      ],
      "metadata": {
        "id": "k7lgegwDWFTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Find out the top 25 titles (2.5 pts)"
      ],
      "metadata": {
        "id": "rcGeZKuIRHe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the top 25 titles? Now that we have the IMDb ratings conveniently stored in a column, display the top 25 titles, together with their IMDb rating:"
      ],
      "metadata": {
        "id": "E-IE_GfsRMOG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "svC-x1ZcRNJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Predicting the genre of movies (40 points)"
      ],
      "metadata": {
        "id": "2Ca4XaEtqvwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll be asked to create a number of features and use them to predict whether a movie is a science fiction movie or not. \n",
        "For this classification task, we'll work with a different part of the movies dataset, which contains more information for each movie."
      ],
      "metadata": {
        "id": "irkcmAfTHTzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/train.csv'"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T12:28:57.151965Z",
          "start_time": "2021-09-27T12:28:57.145452Z"
        },
        "id": "cs0dJMEG1PLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll try to predict whether a movie is a science fiction movie based on the other associated genres for the movie, the people and companies involved in making it, as well as its release date."
      ],
      "metadata": {
        "id": "SIcpNS2GCXUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Adding binary features for genres (15 pts)"
      ],
      "metadata": {
        "id": "IkN5bCjoCPW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in Exercise 1, the data on several columns is in a stringified format. Pre-process the following columns appropriately, as you did with the `genres` column in Part 1 of Exercise 1.\n",
        "```\n",
        "'belongs_to_collection', 'genres', 'production_companies','production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew'\n",
        "```\n",
        " \n",
        "Don't loop explicitly over the rows to perform this preprocessing. Your dataframe should be named `train`."
      ],
      "metadata": {
        "id": "XA00jck22BKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "tHi0Ejxb2bKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the 'genres' column, you can see that movies have a varying number of associated genres."
      ],
      "metadata": {
        "id": "Z57lsGZ5IL7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# this will work only if you've already preprocessed the genres' column into lists of dicts\n",
        "for i, v in enumerate(train.genres.head()):\n",
        "    print(i, v)"
      ],
      "outputs": [],
      "metadata": {
        "id": "amzV_VzSE0VL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the number of movies that have $n$ associated genres, for each $n$ in the dataset. If a movie has no associated genres, assign it the number 0. \n",
        "\n",
        "You have to use Pandas built-in functions only (no explicit looping). For example, you could use `apply()` with an appropriate function to apply to each row. \n",
        "\n",
        "Once you have the counts, visualise them as a bar chart, with one bar per possible number of associated genres, and the height of the bar representing the number of movies with that number of genres.\n"
      ],
      "metadata": {
        "id": "kPDjPDHlInOC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "6cHqZJ8iImh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create our binary features next. Complete the following steps:\n",
        " \n",
        "1.   Transform the `genres` column by replacing its current entries with the list of names of genres occurring in the entries.  For example, the entry \n",
        "```\n",
        "[{'id': 10749, 'name': 'Romance'}, {'id': 35, 'name': 'Comedy'}]\n",
        "```\n",
        "should be transformed into:\n",
        "```\n",
        "['Romance','Comedy']\n",
        "```\n",
        "Empty entries should be transformed into the empty list `[]`.\n",
        "\n",
        "2. Create a separate column (in `train`) for each of the 20 genres, with name `genres_(nameofgenre)` (e.g. `genres_Comedy`). A movie should have a 1 on a genres column if the genre is one of the associated genres for that movie, and a 0 otherwise.\n",
        "    * To get started, consider what operations create a data frame with dimensions as `train` and columns as specified here, based on the list output from step 1. Then combine this data frame with `train`.\n",
        "\n",
        "You have to use Pandas built-in functions only (no explicit looping)."
      ],
      "metadata": {
        "id": "EqA9UQ3rJyBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "EVXMvDv3Mk1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the number of movies per top 20 genre with a chart of your choice."
      ],
      "metadata": {
        "id": "nN65zGfLnSe-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "wEjJJkMZh9mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Adding more binary features (5 pts)"
      ],
      "metadata": {
        "id": "M79tzVdMDfXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've now extracted binary features for all genres associated with a movie. But there's other information that we could use to base our predictions on. \n",
        "\n",
        "The `genres` column is just one out of several columns containing lists of dictionaries as entries. For example, the `production_companies` column also contains lists of dictionaries, providing names of the companies producing the movie. As you just did with genres, add new columns for:\n",
        " \n",
        "1.   The names of the 30 most common production companies\n",
        "2.   The names of the 30 most common production countries\n",
        "3.   The names of the 30 most common actors (`cast` column) \n",
        "4.   The names of the 30 most common crew members\n",
        "5.   The names of the 30 most common keywords\n",
        " \n",
        "We recommend you generalize the functionality implemented in the previous question (e.g. to other columns and to restrict to top 30 most common values)."
      ],
      "metadata": {
        "id": "7iZngZ3ZnAsG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "9sO8Tsqduatn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the result. You should now have a much wider table, with the new columns consisting of binary features."
      ],
      "metadata": {
        "id": "KjFFSEJs93yJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "IyORi5V27Mg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Part 3: Adding numerical date features (5 points)"
      ],
      "metadata": {
        "id": "joEcHikdD5SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create some features based on the release date information. Create a new column storing the value for each of the following  aspects of a release date:\n",
        " \n",
        "```\n",
        "['year', 'weekday', 'month', 'weekofyear', 'day', 'quarter']\n",
        "```\n",
        " \n",
        "As usual, don't iterate explicitly to create these columns."
      ],
      "metadata": {
        "id": "nliC-9woDYd_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "-K5u197bDX1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll drop the columns that will not be used for learning. "
      ],
      "metadata": {
        "id": "KWLi9-BW97VX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train = train.drop(['id', 'homepage', 'original_language',\n",
        "                    'title', 'imdb_id','crew', 'poster_path', \n",
        "                    'release_date', 'status', 'belongs_to_collection',\n",
        "                    'Keywords', 'original_title', 'overview',\n",
        "                    'production_companies', 'production_countries', \n",
        "                    'spoken_languages', 'tagline', 'cast','genres'], \n",
        "                   axis=1)"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T15:27:05.446343Z",
          "start_time": "2021-09-27T15:27:05.426250Z"
        },
        "id": "MbycSRqu8dR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, drop any rows with missing values."
      ],
      "metadata": {
        "id": "lOlV7ho4-OR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "asrzvNYy-NO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Prediction (10 pts)"
      ],
      "metadata": {
        "id": "tV_ANmOH0rQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load the necessary `sklearn` libraries and prepare the training data for learning. Recall that your goal is to predict whether a movie has science fiction as an associated genre. So you're dealing with a binary classification task."
      ],
      "metadata": {
        "id": "9Y1XUwNX0rQL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "9Qpz2Cd60rQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `sklearn` to prepare the training and test sets, setting aside 15% of the data for testing. Call the training input features, training labels, test input features and test labels as follows:\n",
        "\n",
        "```\n",
        "x_train, x_test, y_train, y_test\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dWzqddf90rQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "dDLDQWPl0rQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature scaling is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). Run the following code to feature scale your input data."
      ],
      "metadata": {
        "id": "AKaGZrSuLg1K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.preprocessing import StandardScaler  \n",
        "scaler = StandardScaler()  \n",
        "scaler.fit(x_train)  \n",
        "x_train = scaler.transform(x_train) \n",
        "x_test = scaler.transform(x_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "by0c0S7s0rQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that the shape of your data looks correct."
      ],
      "metadata": {
        "id": "lxX0ugDuNR8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5tJHqw2M0rQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a classifier of your choice. Then report results:\n",
        "* Display the confusion matrix over the test set in absolute numbers.\n",
        "    * These numbers reflect number of true positives, true negatives, false positives and false negatives.\n",
        "* Display a normalized confusion matrix over the test set, so [sensitivity and specificity](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) can be read from the diagonal (off-diagonal will contain type I and type II error rates).\n",
        "    * Note that sensitivity is recall for the positive class (1), whereas specificity is recall for the negative class (0).\n",
        "* State **in free-text** the sensitivity and specificity of your classifier."
      ],
      "metadata": {
        "id": "90SIHxqzN3Ht"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "lIg8WIm3NiKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your explanation here*"
      ],
      "metadata": {
        "id": "lBkWn4WXA-QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Prediction with less leakage (5 points)"
      ],
      "metadata": {
        "id": "oP8IaWa9A-QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Wikipedia, [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.\n",
        "\n",
        "Feature or column-wise leakage is caused by the inclusion of columns which are one of the following: a duplicate label, a proxy for the label, or the label itself\n",
        "\n",
        "Considering we're doing binary classification of whether a movie is science fiction, identify the most prominent cause of feature leakage among the features added during Exercise 3. \n",
        "\n",
        "1) **Argue** for your choice, 2) train a classifier not subject to this feature leakage (it's OK to create a new train/test split) and 3) **report the results** as you did in Part 4."
      ],
      "metadata": {
        "id": "ZKIGA3BOA-QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your explanation here*"
      ],
      "metadata": {
        "id": "Mb7FTGgTA-QS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T14:01:15.648444Z",
          "start_time": "2021-09-27T14:01:15.643363Z"
        },
        "id": "9CzDjF_pA-QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Basic movie recommendation system (20 points)"
      ],
      "metadata": {
        "id": "hc4EOB-gb5pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you'll build a simple movie recommendation system.  The system will take a movie as input and recommend a list of similar movies. In order to recommend similar movies, you will use the correlation between the ratings of movies as a similarity metric. We'll use Pearson's correlation. \n",
        " \n",
        "The data for this exercise is available in the following URLs. It contains basic info about movies, as well as ratings provided by several users."
      ],
      "metadata": {
        "id": "7PqirpLgVdN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "url1 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/ratings.csv'\n",
        "url2 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies.csv'"
      ],
      "outputs": [],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-27T14:49:08.552678Z",
          "start_time": "2021-09-27T14:49:08.547286Z"
        },
        "id": "HOHERjo8cLQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Preparing the ratings data (10 pts)"
      ],
      "metadata": {
        "id": "YOXKd22xXgo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data from these two URLs, and create a single dataframe from them, with the following columns:\n",
        "\n",
        "| userId | movieId | rating | timestamp | title | genres |\n",
        "|--------|---------|--------|-----------|-------|--------|\n",
        "|        |         |        |           |       |        |\n",
        "\n",
        "Call the dataframe `movie_data`."
      ],
      "metadata": {
        "id": "Isn8M65HXi3i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "GwhdEsGUn1zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the correlation between the ratings of movies, create a dataframe where each column is a movie name and each row contains the rating assigned by a specific user to that movie. \n",
        "\n",
        "You'll notice that this dataframe has many NaN values, since each movie is not rated by every user. Call the dataframe `user_ratings`."
      ],
      "metadata": {
        "id": "MFGc9VSzadHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "eTrrVPsrfn1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Finding the most similar movies (10 pts)"
      ],
      "metadata": {
        "id": "hy61Luqyu2Te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each column contains all the user ratings for a particular movie. Let's take the user ratings for the movie Toy Story."
      ],
      "metadata": {
        "id": "M7FBDshDd1j7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "toystory_ratings = user_ratings['Toy Story (1995)']\n",
        "toystory_ratings"
      ],
      "outputs": [],
      "metadata": {
        "id": "6e-9WXAro_4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, find the correlation between the user ratings for Toy Story and the user ratings of all other movies. \n",
        " \n",
        "More specifically, create a dataframe that contains two columns, called `title` and `Correlation`. Each row should contain a movie title $x$, followed by the pairwise correlation between the column of ratings for Toy Story and the column of ratings for $x$.  Drop any rows with null values, and display the resulting dataframe.\n",
        " \n",
        "Use built-in functions to compute correlations and avoid explicit loops."
      ],
      "metadata": {
        "id": "fljIQkJmpCJD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "_yuX1U0Xh0nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the movies by descending order of correlation to find out highly correlated movies at the top. Display the 5 most highly correlated movies.\n"
      ],
      "metadata": {
        "id": "aji7cUw-r-JG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "FU0Zm9fjg4BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you computed correlations correctly, you will find that the recommended movies are not very well known. We can generate more popular recommendations by finding highly correlated movies that have a sensible number of ratings. \n",
        " \n",
        "Add a column to your correlation table, called `rating_counts`, which stores the number of ratings received by each movie."
      ],
      "metadata": {
        "id": "qrvD_u63sVdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "WvMKUmBFg-Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now find the 5 movies with the highest correlation with Toy Story, which have strictly more than 100 ratings. Display the result below. "
      ],
      "metadata": {
        "id": "b_20nfFvt-7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# your code goes here"
      ],
      "outputs": [],
      "metadata": {
        "id": "KvE3c2lMhHNz"
      }
    }
  ]
}