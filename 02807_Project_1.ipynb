{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlsPJUw7wCWZ"
   },
   "source": [
    "# 02807: Project 1\n",
    " \n",
    "## Practical information\n",
    " \n",
    "* This project must be completed in groups of 3 students.\n",
    "    * The group must be registered on the course site on DTU Learn: My Course > Groups\n",
    "* This project must be handed in as a jupyter notebook to the course site on DTU Learn. \n",
    "    * Go to the Course Content > Assignments tab to upload your submission. \n",
    "* This project is due on Monday, November 1, 20:00.\n",
    "\n",
    "## Submission rules\n",
    "\n",
    "* Each group has to hand in *one* notebook (`.ipynb`) with their solutions, including a filled out Contribution table (see below).\n",
    "* Your solution must be written in Python.\n",
    "* For each question you should use the cells provided (\"`# your code goes here`\") for your solution\n",
    "    * It is allowed to add code cells within a question block, but consider if it's really necessary.\n",
    "* You should not remove the problem statements, and you should not modify the structure of the notebook.\n",
    "* Your notebook should be runnable and readable from top to bottom.\n",
    "    * Meaning that your code cells work when run in order (from top to bottom).\n",
    "    * Output of any cell depends only on itself and cells above it.\n",
    "* Your notebook should be submitted after having been run from top to bottom.\n",
    "    * This means outputs are interpretable without necessarily running your cells.\n",
    "    * The simplest way to achieve this is using the jupyter menu item Kernel > Restart & Run All just prior to submission. If any cell fails when you do this, your notebook is not ready for submission.\n",
    "* Failure to comply may make it impossible for us to evaluate your submission properly, which will likely negatively impact the points awarded.\n",
    "    \n",
    " \n",
    "## Colaboration policy\n",
    " \n",
    "* It is not allowed to collaborate on the exercises with students outside your group, except for discussing the text of the exercise with teachers and fellow students enrolled on the course in the same semester. \n",
    "* It is not allowed to exchange, hand-over or in any other way communicate solutions or parts of solutions to the exercises. \n",
    "* It is not allowed to use solutions from similar courses, or solutions found elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP30rwxHDQyG"
   },
   "source": [
    "## Contribution table and grading\n",
    "\n",
    "* The total amount of points in the project is 110.\n",
    "* You have to indicate who has solved each part of each exercise in a **contribution table**. \n",
    "* The following is an example of a contributions table:\n",
    "\n",
    "|        | Exercise 1 | Exercise 2 | Exercise 3 | Exercise 4 |\n",
    "|--------|------------|------------|------------|------------|\n",
    "| **Part 1** | John       |    Mary        |     Ann       |   Mary, Ann         |\n",
    "| **Part 2** |     Mary       |    Mary        |   Ann         |    John, Ann        |\n",
    "| **Part 3** |     John, Mary, Ann       |      John, Ann      |   John         | **n.a.**      |\n",
    "| **Part 4** | **n.a.**       |  Ann          |     John, Mary       | **n.a.**       |\n",
    "| **Part 5** | **n.a.**     | John, Mary, Ann           | John       | **n.a.**       |\n",
    "\n",
    "* A group member can take credit for solving a part of an exercise only if they have contributed **substantially** to the solution. \n",
    "    * Simple contributions, such as correcting a small bug or double-checking the results of functions, are not sufficient for taking credit for a solution.\n",
    "    * Several group members can take credit for the same solution if they all have contributed substantially to it.\n",
    "* Each group member must contribute **at least 50 points**. \n",
    "    * If no name is provided for an exercise's part, **all group members** are considered contributors to it.\n",
    "* Group members should decide amongst themselves how to collaborate on the project to meet the above-mentioned constraints.  \n",
    "* Scores are individual. The score $\\text{score}(m)$ for a group member $m$ ranges from 0 to 10 and is calculated as follows: \n",
    "\n",
    "  * $\\text{individual-score}(m) = \\frac{\\text{total number of points for the parts correctly solved by }m}{\\text{total number of points for the parts contributed by }m}$\n",
    "\n",
    "  * $\\text{group-score} = \\frac{\\text{total number of points correctly solved by any group member}}{\\text{total number of points in the project}}$\n",
    "\n",
    "  * $\\text{score}(m) =  7.5 \\cdot \\text{individual-score}(m) + 2.5 \\cdot \\text{group-score}$\n",
    "\n",
    "* **Example**: in the contribution table above, suppose that all parts are solved correctly except for those of Exercise 4, which are both wrong. Then Ann's score is calculated as follows:\n",
    "\n",
    "  * $\\text{individual-score}(Ann) = \\frac{2.5+12.5+12.5+2.5+15+5}{2.5+12.5+12.5+2.5+15+5 + 10 + 10} = \\frac{50}{70} = 0.714$\n",
    "\n",
    "  * $\\text{group-score} = \\frac{90}{110} = 0.818$\n",
    "\n",
    "  * $\\text{score}(Ann) = 7.5\\cdot 0.714 + 2.5 \\cdot 0.818 = 7.4$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vklet8XdRGVV"
   },
   "source": [
    "# Group declaration table \n",
    "\n",
    "This table must be filled before submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T15:03:19.791917Z",
     "start_time": "2021-09-27T15:03:19.764408Z"
    },
    "id": "chiXA3CzRSA1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exercise 1</th>\n",
       "      <th>Exercise 2</th>\n",
       "      <th>Exercise 3</th>\n",
       "      <th>Exercise 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Part 1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 4</th>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Part 5</th>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Exercise 1 Exercise 2 Exercise 3 Exercise 4\n",
       "Part 1                                            \n",
       "Part 2                                            \n",
       "Part 3                                         ---\n",
       "Part 4        ---                              ---\n",
       "Part 5        ---                              ---"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'Exercise 1' : [\"\", \"\", \"\", \"---\", \"---\"], \n",
    "     'Exercise 2' : [\"\", \"\", \"\", \"\", \"\"],\n",
    "     'Exercise 3' : [\"\", \"\", \"\", \"\", \"\"], \n",
    "     'Exercise 4' : [\"\", \"\", \"---\", \"---\", \"---\"],\n",
    "     } \n",
    "  \n",
    "ct = pd.DataFrame(d, index =['Part 1','Part 2','Part 3','Part 4','Part 5']) \n",
    "\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7aa1b0ad6979877450f9cd89e1e37289b51cf6e",
    "id": "CF8tC7Z8CgbW"
   },
   "source": [
    "# Introduction to the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO8N4lj29u9w"
   },
   "source": [
    "![link text](https://ph-files.imgix.net/069dd825-cddf-4048-adde-8e81396c2c68?auto=format)\n",
    "\n",
    "\n",
    "You will be working with datasets obtained through the [The Movie Database (TMDb) API](https://developers.themoviedb.org/3/getting-started/introduction). The first dataset is part of the MovieLens Latest Full Dataset, comprising 26 million ratings on 45.000 movies from 27.000 users. Let's look at the features in this dataset.\n",
    "\n",
    "**Features**\n",
    "\n",
    "* **adult**: Indicates if the movie is X-Rated.\n",
    "* **belongs_to_collection**: A stringified dictionary with info on the movie series a particular film belongs to (e.g.: Lord of the Rings).\n",
    "* **budget**: The movie budget in dollars.\n",
    "* **genres**: A stringified list of dictionaries describing all genres associated with the movie.\n",
    "* **homepage**: The movie's official homepage.\n",
    "* **id**: An identifier for the movie.\n",
    "* **imdb_id**: IMDB's identifier for the movie.\n",
    "* **original_language**: The language in which the movie was shot.\n",
    "* **original_title**: The original title of the movie.\n",
    "* **overview**: A brief text about the movie.\n",
    "* **popularity**: A Popularity Score given by TMDb.\n",
    "* **poster_path**: The URL of the poster image.\n",
    "* **production_companies**: A stringified list of production companies involved with making of the movie.\n",
    "* **production_countries**: A stringified list of countries in which the movie was produced.\n",
    "* **release_date**: Release date of the movie in theaters.\n",
    "* **revenue**: The total revenue of the movie in dollars.\n",
    "* **runtime**: The runtime of the movie in minutes.\n",
    "* **spoken_languages**: A stringified list of languages spoken in the film.\n",
    "* **status**: The status of the movie (Released, To Be Released, etc.)\n",
    "* **tagline**: The movie's tagline.\n",
    "* **title**: The official title of the movie.\n",
    "* **video**: Indicates whether there is a video of the movie in TMDb.\n",
    "* **vote_average**: The average rating of the movie, on a 0-10 scale.\n",
    "* **vote_count**: The number of votes by users, as counted by TMDb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b418588e3f9139f74cb3a9546f5dca49729579b",
    "id": "2Clue5Z_Cgbc"
   },
   "source": [
    "# Imports\n",
    "\n",
    "First, let's make sure to import Pandas and NumPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T10:09:32.802462Z",
     "start_time": "2021-09-27T10:09:30.598648Z"
    },
    "id": "A0K3Aw3eAf2B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFlHk-e0BZME"
   },
   "source": [
    "# Exercise 1: Loading, preprocessing and cleaning the data (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGJnqtQD1BOs"
   },
   "source": [
    "Read the movie dataset from the following URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T10:09:34.147572Z",
     "start_time": "2021-09-27T10:09:34.145160Z"
    },
    "id": "sQb46KRIAkOB"
   },
   "outputs": [],
   "source": [
    "url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies_metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQrm5PleClKz"
   },
   "source": [
    "## Part 1: Reading and preprocessing the data (10 pts)\n",
    "\n",
    "Pandas infers a data type for raw data from a `.csv`, defaulting to string type when no other `dtype` could be established. For example, the `genres` column in our dataset is read as a string with a *stringified* list of dictionaries as cell content. \n",
    "\n",
    "Some preprocessing steps are therefore needed, to convert the columns into their proper data types.\n",
    "\n",
    "Write a function `load_movies_data()` that reads the URL into a Pandas DataFrame and preprocesses its columns to ensure that:\n",
    "\n",
    "1. Data in the `release_date` column consists of Pandas `Timestamp` objects, except for missing values. For example, executing a code cell with `df.release_date[0]` should display the output `Timestamp('1995-10-30 00:00:00')`.\n",
    "\n",
    "2. Data in `belongs_to_collection` consists of dictionaries, except for missing values.\n",
    "\n",
    "3. Data in `genres`, `production_companies` and `production_countries` consists of lists of dictionaries, except for missing values. \n",
    "\n",
    "For example, executing a code cell with `df.genres[0]` should display the output \n",
    "```\n",
    "[{'id': 16, 'name': 'Animation'},\n",
    " {'id': 35, 'name': 'Comedy'},\n",
    " {'id': 10751, 'name': 'Family'}]\n",
    "```\n",
    "which is a list type, not a string. The elements of the list are dictionaries (executing `df.genres[0][0]['name']` returns `'Animation'`). \n",
    "\n",
    "**Hint**: for items 2 and 3, you should use `ast.literal_eval`.\n",
    "\n",
    "These conversions can be performed using Pandas' built-in functions and/or calling Pandas' `apply()` with appropriate arguments. Avoid explicit looping. You'll be asked below to time the loading and preprocessing step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_eval(x):\n",
    "    if not pd.isna(x):\n",
    "        return ast.literal_eval(x)\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_movies_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "    df['belongs_to_collection'] = df['belongs_to_collection'].apply(literal_eval)\n",
    "    df['genres'] = df['genres'].apply(literal_eval)\n",
    "    df['production_companies'] = df['production_companies'].apply(literal_eval)\n",
    "    df['production_countries'] = df['production_countries'].apply(literal_eval)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZvSPPdzfScL"
   },
   "source": [
    "Now call `load_movies_data()` and load the data into a DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "4-eOSqlhD-8J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = load_movies_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnelY1bZzj-J"
   },
   "source": [
    "Display the DataFrame. You should check that it looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "tP6zpeLxu4J-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget</th>\n",
       "      <td>30000000</td>\n",
       "      <td>65000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homepage</th>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>862</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_id</th>\n",
       "      <td>tt0114709</td>\n",
       "      <td>tt0113497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_language</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_title</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overview</th>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>21.946943</td>\n",
       "      <td>17.015539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poster_path</th>\n",
       "      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n",
       "      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_companies</th>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_countries</th>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>1995-10-30 00:00:00</td>\n",
       "      <td>1995-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>373554033.0</td>\n",
       "      <td>262797249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtime</th>\n",
       "      <td>81.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoken_languages</th>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>Released</td>\n",
       "      <td>Released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagline</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Jumanji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote_average</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote_count</th>\n",
       "      <td>5415.0</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0  \\\n",
       "adult                                                              False   \n",
       "belongs_to_collection  {'id': 10194, 'name': 'Toy Story Collection', ...   \n",
       "budget                                                          30000000   \n",
       "genres                 [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "homepage                            http://toystory.disney.com/toy-story   \n",
       "id                                                                   862   \n",
       "imdb_id                                                        tt0114709   \n",
       "original_language                                                     en   \n",
       "original_title                                                 Toy Story   \n",
       "overview               Led by Woody, Andy's toys live happily in his ...   \n",
       "popularity                                                     21.946943   \n",
       "poster_path                             /rhIRbceoE9lR4veEXuwCC2wARtG.jpg   \n",
       "production_companies      [{'name': 'Pixar Animation Studios', 'id': 3}]   \n",
       "production_countries   [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "release_date                                         1995-10-30 00:00:00   \n",
       "revenue                                                      373554033.0   \n",
       "runtime                                                             81.0   \n",
       "spoken_languages                [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "status                                                          Released   \n",
       "tagline                                                              NaN   \n",
       "title                                                          Toy Story   \n",
       "video                                                              False   \n",
       "vote_average                                                         7.7   \n",
       "vote_count                                                        5415.0   \n",
       "\n",
       "                                                                       1  \n",
       "adult                                                              False  \n",
       "belongs_to_collection                                                NaN  \n",
       "budget                                                          65000000  \n",
       "genres                 [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
       "homepage                                                             NaN  \n",
       "id                                                                  8844  \n",
       "imdb_id                                                        tt0113497  \n",
       "original_language                                                     en  \n",
       "original_title                                                   Jumanji  \n",
       "overview               When siblings Judy and Peter discover an encha...  \n",
       "popularity                                                     17.015539  \n",
       "poster_path                             /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg  \n",
       "production_companies   [{'name': 'TriStar Pictures', 'id': 559}, {'na...  \n",
       "production_countries   [{'iso_3166_1': 'US', 'name': 'United States o...  \n",
       "release_date                                         1995-12-15 00:00:00  \n",
       "revenue                                                      262797249.0  \n",
       "runtime                                                            104.0  \n",
       "spoken_languages       [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  \n",
       "status                                                          Released  \n",
       "tagline                        Roll the dice and unleash the excitement!  \n",
       "title                                                            Jumanji  \n",
       "video                                                              False  \n",
       "vote_average                                                         6.9  \n",
       "vote_count                                                        2413.0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuzjOV7ffbpR"
   },
   "source": [
    "## Part 2: Timing your function (2.5 pts)\n",
    "\n",
    "Time the performance of your function. To get the points for this part, the time reported below must not exceed 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "aIYWL17bO2Ih"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moeso\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1158: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  time_number = timer.timeit(number)\n",
      "C:\\Users\\moeso\\Anaconda3\\lib\\timeit.py:204: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  t = self.timeit(number)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 s ± 83.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Time (s): 10.31223510000018\n"
     ]
    }
   ],
   "source": [
    "load_time = %timeit -o -r 3 load_movies_data(url)\n",
    "print(\"Time (s):\", load_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sVQeTkLYI2b"
   },
   "source": [
    "## Part 3: Cleaning the data (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ydbZ-KFYlRX"
   },
   "source": [
    "Filter/drop all rows in `df` meeting any of these conditions:\n",
    "* The `adult` value is not `'False'`\n",
    "* The `vote_count` value is missing\n",
    "* The `vote_average` value is missing\n",
    "\n",
    "Do not loop over rows to perform these checks. Use Pandas' built-in functionality to do so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some checks on the values of the `adult` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False', 'True', ' - Written by Ørnås',\n",
       "       ' Rune Balot goes to a casino connected to the October corporation to try to wrap up her case once and for all.',\n",
       "       ' Avalanche Sharks tells the story of a bikini contest that turns into a horrifying affair when it is hit by a shark avalanche.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.adult.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through manual investigation in the .csv file it is noted that there are 3 movies with line breaks in the description which causes the parser to handle it as a new line in the dataframe. We decided to drop those rows and the row before those to eliminate the affected rows. Removing 3 movies should not be significant for our further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19730</th>\n",
       "      <td>- Written by Ørnås</td>\n",
       "      <td>0.065736</td>\n",
       "      <td>/ff9qCepilowshEtG2GYWwzt2bs4.jpg</td>\n",
       "      <td>[{'name': 'Carousel Productions', 'id': 11176}...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...</td>\n",
       "      <td>1997-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29503</th>\n",
       "      <td>Rune Balot goes to a casino connected to the ...</td>\n",
       "      <td>1.931659</td>\n",
       "      <td>/zV8bHuSL6WXoD6FWogP9j4x80bL.jpg</td>\n",
       "      <td>[{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[{'iso_639_1': 'ja', 'name': '日本語'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35587</th>\n",
       "      <td>Avalanche Sharks tells the story of a bikini ...</td>\n",
       "      <td>2.185485</td>\n",
       "      <td>/zaSf5OG7V8X8gqFvly88zDdRm46.jpg</td>\n",
       "      <td>[{'name': 'Odyssey Media', 'id': 17161}, {'nam...</td>\n",
       "      <td>[{'iso_3166_1': 'CA', 'name': 'Canada'}]</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   adult  \\\n",
       "19730                                 - Written by Ørnås   \n",
       "29503   Rune Balot goes to a casino connected to the ...   \n",
       "35587   Avalanche Sharks tells the story of a bikini ...   \n",
       "\n",
       "      belongs_to_collection                            budget  \\\n",
       "19730              0.065736  /ff9qCepilowshEtG2GYWwzt2bs4.jpg   \n",
       "29503              1.931659  /zV8bHuSL6WXoD6FWogP9j4x80bL.jpg   \n",
       "35587              2.185485  /zaSf5OG7V8X8gqFvly88zDdRm46.jpg   \n",
       "\n",
       "                                                  genres  \\\n",
       "19730  [{'name': 'Carousel Productions', 'id': 11176}...   \n",
       "29503  [{'name': 'Aniplex', 'id': 2883}, {'name': 'Go...   \n",
       "35587  [{'name': 'Odyssey Media', 'id': 17161}, {'nam...   \n",
       "\n",
       "                                                homepage          id imdb_id  \\\n",
       "19730  [{'iso_3166_1': 'CA', 'name': 'Canada'}, {'iso...  1997-08-20       0   \n",
       "29503  [{'iso_3166_1': 'US', 'name': 'United States o...  2012-09-29       0   \n",
       "35587           [{'iso_3166_1': 'CA', 'name': 'Canada'}]  2014-01-01       0   \n",
       "\n",
       "      original_language                            original_title  overview  \\\n",
       "19730             104.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "29503              68.0      [{'iso_639_1': 'ja', 'name': '日本語'}]  Released   \n",
       "35587              82.0  [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "       ... release_date revenue runtime spoken_languages status  tagline  \\\n",
       "19730  ...          NaT     NaN     NaN              NaN    NaN      NaN   \n",
       "29503  ...          NaT     NaN     NaN              NaN    NaN      NaN   \n",
       "35587  ...          NaT     NaN     NaN              NaN    NaN      NaN   \n",
       "\n",
       "       title video vote_average vote_count  \n",
       "19730    NaN   NaN          NaN        NaN  \n",
       "29503    NaN   NaN          NaN        NaN  \n",
       "35587    NaN   NaN          NaN        NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_index = df[~df.adult.isin(['False', 'True'])].index\n",
    "df[~df.adult.isin(['False', 'True'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(bad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop the X rated movies and NaN values in `vote_count` and `vote_average`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "Qtb7AaaVY5nm"
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df.adult == 'True'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['vote_count', 'vote_average'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT8jdILukiBF"
   },
   "source": [
    "# Exercise 2: Computing IMDb's ratings (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84SE_eMzkyC1"
   },
   "source": [
    "The Top Rated 250 titles in IMDb are calculated using [a formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#calculatetop) that takes into account the number of votes that a title has received, the minimum votes required to be on the list, and the mean vote for all titles. The rating for a title is given as follows:\n",
    "\n",
    "$$ \\text{weighted rating } = \\left(\\frac{v}{v+m} \\cdot R\\right) + \\left(\\frac{m}{v+m} \\cdot C\\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$m$ = the minimum number of votes required to be listed in the Top Rated ranking. We'll let $m=1000$.\n",
    "\n",
    "$v$ = the number of votes received by the title (the title's **`vote_count`** value)\n",
    "\n",
    "$R$ = the average rating for the title (the title's **`vote_average`** value)\n",
    "\n",
    "$C$ = the mean vote across the whole list (the mean over the **`vote_average`** column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85J4HDO2rieA"
   },
   "source": [
    "We are going to compute the ratings for movies that could be listed in IMDb's Top Rated 250 ranking.  We want to do this as efficiently as possible. As a baseline for benchmarking, we'll use an approach that explicitly loops and indexes over the rows of the dataset and computes the weighted rating for the corresponding movie (if the movie has more than 1000 votes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T10:27:52.905697Z",
     "start_time": "2021-09-27T10:27:52.800529Z"
    },
    "id": "MyYhLdBksTec"
   },
   "outputs": [],
   "source": [
    "C = df['vote_average'].mean()\n",
    "m = 1000\n",
    "\n",
    "def weighted_rating(row):\n",
    "    if row['vote_count'] > m:\n",
    "        v = row['vote_count']\n",
    "        R = row['vote_average']\n",
    "        return (v/(v+m) * R) + (m/(v+m) * C)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def weighted_rating_loop(df):\n",
    "    rating_list = []\n",
    "    for i in range(len(df)):\n",
    "        rating = weighted_rating(df.iloc[i])\n",
    "        rating_list.append(rating)\n",
    "    df['imdb_rating'] = rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIsei1w4r9Jz"
   },
   "outputs": [],
   "source": [
    "weighted_rating_loop(df)\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdlffrsJyHvI"
   },
   "source": [
    "Let's look at the average performance of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su__dMpZyX5W"
   },
   "outputs": [],
   "source": [
    "basic_time = %timeit -r 3 -o weighted_rating_loop(df)\n",
    "print(\"Best time:\", basic_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPjyKJ2zzPoQ"
   },
   "source": [
    "In the remaining parts of the exercise, you are going to be asked to come up with alternative ways to compute the ratings, using various methodologies. Let's create a score board to keep track of performance. Here's a description of the rows:\n",
    "\n",
    "*   **Best single run time (s)**:  The best time used by your solution, in seconds.\n",
    "*   **Marginal performance improvement**: The time improvement of your current solution over its immediately preceding solution. Given by: $\\frac{\\text{best single run time (s) of previous solution}}{\\text{best single run time (s) of current solution}}$\n",
    "*   **Performance improvement over basic looping**:  The time improvement over our baseline solution. Given by: $\\frac{\\text{best single run time (s) of weighted_rating_loop}}{\\text{best single run time (s) of current solution}}$\n",
    "*   **Best single run time (s, teacher)**: The time of a solution provided by the teacher. \n",
    "*   **Marginal performance improvement (teacher)**: The time improvement of the teacher's solution over its immediately preceding solution. \n",
    "*   **Performance improvement over basic looping (teacher)**:  The teacher's solution improvement over the baseline solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T11:03:14.455052Z",
     "start_time": "2021-09-27T11:03:14.442251Z"
    },
    "id": "fV-xfrs53NBF"
   },
   "outputs": [],
   "source": [
    "timing_data = {\n",
    "    'Best single run time (s)': [basic_time.best, np.nan, np.nan, np.nan,np.nan],\n",
    "    'Marginal performance improvement': [np.nan,np.nan, np.nan, np.nan,np.nan],\n",
    "    'Performance improvement over basic looping': np.nan,\n",
    "    'Best single run time (s, teacher)': [9.37, 3.87, 0.562, 0.0054, 0.00084],\n",
    "    'Marginal performance improvement (teacher)': [np.nan, 'x2.42', 'x6.88', 'x103.8', 'x6.45'],\n",
    "    'Performance improvement over basic looping (teacher)': [np.nan, 'x2.42', 'x16.69', 'x1732.17','x11172.98']\n",
    "}\n",
    "\n",
    "indices = ['Basic looping', 'Iterrows looping', 'apply()', 'Pandas vectorisation', 'NumPy vectorisation']\n",
    "timings = pd.DataFrame(timing_data, index=indices)\n",
    "timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfD0eUlHgz3l"
   },
   "source": [
    "**The grading for the following parts works as follows.**\n",
    "\n",
    "Let $m$ be the marginal performance improvement for the teacher's solution over basic looping, and let $m'$ be the marginal performance improvement for your solution over `basic_time`. If a part gives $n$ points, then you will get the $n$ points if $m' \\geq 0.4 m$, and 0 points otherwise.\n",
    "\n",
    "You don't get extra points for performing faster than the teacher's solution. But this is of course possible and you should feel free to optimise away as much as you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkiLI2QT7oNY"
   },
   "source": [
    "## Part 1: Looping with `iterrows` (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZIqPIf743q"
   },
   "source": [
    "Define a function `weighted_rating_iterrows(df)` that computes the ratings by looping over rows with the built-in iterator `iterrows`, and stores the results in a new column of the DataFrame called called `imdb_rating_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4dTxRfW6Gc4"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsvOtN6y8Ycg"
   },
   "source": [
    "Call the function and make sure that it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLKzzVP86bza"
   },
   "outputs": [],
   "source": [
    "weighted_rating_iterrows(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_iter, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC-m0iR48jM6"
   },
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9y3BWusJ8y70"
   },
   "outputs": [],
   "source": [
    "iterrows_time = %timeit -r 3 -o weighted_rating_iterrows(df)\n",
    "print(\"Best time:\", iterrows_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HexMOOCB82e_"
   },
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SQRS_gdJCbM"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-FhuhB99em4"
   },
   "source": [
    "## Part 2: Using `apply()`. (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ294FYn9qhO"
   },
   "source": [
    "Define a function `weighted_rating_apply(df)` that computes the ratings using Pandas' `apply()` function, and stores the results in a new column of the DataFrame called `imdb_rating_apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk3SdbQs8ghG"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBgP1e1uCMlF"
   },
   "source": [
    "Call the function and make sure that it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUaYXC_RCMlK"
   },
   "outputs": [],
   "source": [
    "weighted_rating_apply(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_apply, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9jjZI14CMlO"
   },
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqggBfTMCMlP"
   },
   "outputs": [],
   "source": [
    "apply_time = %timeit -r 3 -o weighted_rating_apply(df)\n",
    "print(\"Best time:\", apply_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DzMnzf4CMlS"
   },
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4RSuVOYV0JZ"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZHPgFMsED_6"
   },
   "source": [
    "## Part 3: Vectorised solution with Pandas (12.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI7zQxGNGZnX"
   },
   "source": [
    "Let's find a vectorised solution using Pandas. You have to define a function `weighted_rating_pandas(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_pandas`. Use Pandas operations only: don't transform your data into NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqIXsMGFGZnY"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKVGubslGZna"
   },
   "source": [
    "Call the function and make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXf4KAj1GZna"
   },
   "outputs": [],
   "source": [
    "weighted_rating_pandas(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_pandas, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scNFR7X8GZnc"
   },
   "source": [
    "Time the performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbhwZZ0mGZnf"
   },
   "outputs": [],
   "source": [
    "pandas_time = %timeit -r 3 -o weighted_rating_pandas(df)\n",
    "print(\"Best time:\", pandas_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsqz0kUJGZnh"
   },
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxCI0nUXV3Lk"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvwaE7pIjzEa"
   },
   "source": [
    "Time to reflect on your solution. Do the following: \n",
    " \n",
    "* Explain in words what your function does and why it is a vectorised solution. In particular, break down each step involving ufuncs, broadcasting and other vectorized calls. \n",
    "    * If your explanation has major errors, we will substract points for this part.\n",
    " \n",
    "* Display profiler output and give an analysis of what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQHB_JqeV52E"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DngbQA2eV770"
   },
   "source": [
    "*Your explanation goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLwJEzATEKwi"
   },
   "source": [
    "## Part 4: Vectorised solution with NumPy (12.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrAZ4OI2EPk8"
   },
   "source": [
    "Let's find a vectorised solution that uses NumPy to speed up the calculations. You have to define a function `weighted_rating_numpy(df)` that computes the ratings in a vectorised way and stores them in a new column of the DataFrame called `imdb_rating_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sJlkDYAzQr8"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2pAc_GEEudy"
   },
   "source": [
    "Call the function and make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IALbcsKO2RNt"
   },
   "outputs": [],
   "source": [
    "weighted_rating_numpy(df)\n",
    "\n",
    "pd.testing.assert_series_equal(\n",
    "    df.imdb_rating, df.imdb_rating_numpy, check_names=False\n",
    ")\n",
    "\n",
    "columns_to_show = ['id', 'original_title'] + \\\n",
    "                  list(df.columns[df.columns.str.startswith('imdb_rating')])\n",
    "df[columns_to_show].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0ebRPwiFAfo"
   },
   "source": [
    "Time the best performance of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWe52oAQ6l8R"
   },
   "outputs": [],
   "source": [
    "numpy_time = %timeit -r 3 -o weighted_rating_numpy(df)\n",
    "print(\"Best time:\", numpy_time.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB7tkhUDFAfr"
   },
   "source": [
    "Update the score board with the best time, marginal and overall performance change you have obtained. Display the updated table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8MBiqnvushL"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RSyEDTvA-QQ"
   },
   "source": [
    "Time to reflect on your solution. Do the following: \n",
    " \n",
    "* Explain in words what your function does and why it is a vectorised solution. In particular, break down each step involving ufuncs, broadcasting and other vectorized calls. \n",
    "    * If your explanation has major errors, we will substract points for this part.\n",
    "    * If applicable, you may refer back to the explanation you gave for `weighted_rating_pandas`.\n",
    " \n",
    "* Display profiler output and give an analysis of what you see.\n",
    "    * Contrast your findings with those from `weighted_rating_pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FV8aYhv5WEqA"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7lgegwDWFTt"
   },
   "source": [
    "*Your explanation goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcGeZKuIRHe7"
   },
   "source": [
    "## Part 5: Find out the top 25 titles (2.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-IE_GfsRMOG"
   },
   "source": [
    "What are the top 25 titles? Now that we have the IMDb ratings conveniently stored in a column, display the top 25 titles, together with their IMDb rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svC-x1ZcRNJ4"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ca4XaEtqvwt"
   },
   "source": [
    "# Exercise 3: Predicting the genre of movies (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irkcmAfTHTzR"
   },
   "source": [
    "In this exercise, you'll be asked to create a number of features and use them to predict whether a movie is a science fiction movie or not. \n",
    "For this classification task, we'll work with a different part of the movies dataset, which contains more information for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T12:28:57.151965Z",
     "start_time": "2021-09-27T12:28:57.145452Z"
    },
    "id": "cs0dJMEG1PLL"
   },
   "outputs": [],
   "source": [
    "train_url = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIcpNS2GCXUi"
   },
   "source": [
    "You'll try to predict whether a movie is a science fiction movie based on the other associated genres for the movie, the people and companies involved in making it, as well as its release date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkN5bCjoCPW9"
   },
   "source": [
    "## Part 1: Adding binary features for genres (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XA00jck22BKq"
   },
   "source": [
    "As in Exercise 1, the data on several columns is in a stringified format. Pre-process the following columns appropriately, as you did with the `genres` column in Part 1 of Exercise 1.\n",
    "```\n",
    "'belongs_to_collection', 'genres', 'production_companies','production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew'\n",
    "```\n",
    " \n",
    "Don't loop explicitly over the rows to perform this preprocessing. Your dataframe should be named `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHi0Ejxb2bKM"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z57lsGZ5IL7b"
   },
   "source": [
    "Looking at the 'genres' column, you can see that movies have a varying number of associated genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amzV_VzSE0VL"
   },
   "outputs": [],
   "source": [
    "# this will work only if you've already preprocessed the genres' column into lists of dicts\n",
    "for i, v in enumerate(train.genres.head()):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPDjPDHlInOC"
   },
   "source": [
    "Count the number of movies that have $n$ associated genres, for each $n$ in the dataset. If a movie has no associated genres, assign it the number 0. \n",
    "\n",
    "You have to use Pandas built-in functions only (no explicit looping). For example, you could use `apply()` with an appropriate function to apply to each row. \n",
    "\n",
    "Once you have the counts, visualise them as a bar chart, with one bar per possible number of associated genres, and the height of the bar representing the number of movies with that number of genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cHqZJ8iImh1"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqA9UQ3rJyBQ"
   },
   "source": [
    "Let's create our binary features next. Complete the following steps:\n",
    " \n",
    "1.   Transform the `genres` column by replacing its current entries with the list of names of genres occurring in the entries.  For example, the entry \n",
    "```\n",
    "[{'id': 10749, 'name': 'Romance'}, {'id': 35, 'name': 'Comedy'}]\n",
    "```\n",
    "should be transformed into:\n",
    "```\n",
    "['Romance','Comedy']\n",
    "```\n",
    "Empty entries should be transformed into the empty list `[]`.\n",
    "\n",
    "2. Create a separate column (in `train`) for each of the 20 genres, with name `genres_(nameofgenre)` (e.g. `genres_Comedy`). A movie should have a 1 on a genres column if the genre is one of the associated genres for that movie, and a 0 otherwise.\n",
    "    * To get started, consider what operations create a data frame with dimensions as `train` and columns as specified here, based on the list output from step 1. Then combine this data frame with `train`.\n",
    "\n",
    "You have to use Pandas built-in functions only (no explicit looping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVXMvDv3Mk1t"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN65zGfLnSe-"
   },
   "source": [
    "Visualise the number of movies per top 20 genre with a chart of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEjJJkMZh9mF"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M79tzVdMDfXL"
   },
   "source": [
    "## Part 2: Adding more binary features (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iZngZ3ZnAsG"
   },
   "source": [
    "You've now extracted binary features for all genres associated with a movie. But there's other information that we could use to base our predictions on. \n",
    "\n",
    "The `genres` column is just one out of several columns containing lists of dictionaries as entries. For example, the `production_companies` column also contains lists of dictionaries, providing names of the companies producing the movie. As you just did with genres, add new columns for:\n",
    " \n",
    "1.   The names of the 30 most common production companies\n",
    "2.   The names of the 30 most common production countries\n",
    "3.   The names of the 30 most common actors (`cast` column) \n",
    "4.   The names of the 30 most common crew members\n",
    "5.   The names of the 30 most common keywords\n",
    " \n",
    "We recommend you generalize the functionality implemented in the previous question (e.g. to other columns and to restrict to top 30 most common values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sO8Tsqduatn"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjFFSEJs93yJ"
   },
   "source": [
    "Check the result. You should now have a much wider table, with the new columns consisting of binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyORi5V27Mg0"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joEcHikdD5SY"
   },
   "source": [
    " ## Part 3: Adding numerical date features (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nliC-9woDYd_"
   },
   "source": [
    "Next, we'll create some features based on the release date information. Create a new column storing the value for each of the following  aspects of a release date:\n",
    " \n",
    "```\n",
    "['year', 'weekday', 'month', 'weekofyear', 'day', 'quarter']\n",
    "```\n",
    " \n",
    "As usual, don't iterate explicitly to create these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-K5u197bDX1A"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWLi9-BW97VX"
   },
   "source": [
    "Next, we'll drop the columns that will not be used for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T15:27:05.446343Z",
     "start_time": "2021-09-27T15:27:05.426250Z"
    },
    "id": "MbycSRqu8dR5"
   },
   "outputs": [],
   "source": [
    "train = train.drop(['id', 'homepage', 'original_language',\n",
    "                    'title', 'imdb_id','crew', 'poster_path', \n",
    "                    'release_date', 'status', 'belongs_to_collection',\n",
    "                    'Keywords', 'original_title', 'overview',\n",
    "                    'production_companies', 'production_countries', \n",
    "                    'spoken_languages', 'tagline', 'cast','genres'], \n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOlV7ho4-OR9"
   },
   "source": [
    "Lastly, drop any rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asrzvNYy-NO4"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV_ANmOH0rQJ"
   },
   "source": [
    "## Part 4: Prediction (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Y1XUwNX0rQL"
   },
   "source": [
    "Let's load the necessary `sklearn` libraries and prepare the training data for learning. Recall that your goal is to predict whether a movie has science fiction as an associated genre. So you're dealing with a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qpz2Cd60rQM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWzqddf90rQR"
   },
   "source": [
    "Use `sklearn` to prepare the training and test sets, setting aside 15% of the data for testing. Call the training input features, training labels, test input features and test labels as follows:\n",
    "\n",
    "```\n",
    "x_train, x_test, y_train, y_test\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDLDQWPl0rQS"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKaGZrSuLg1K"
   },
   "source": [
    "Feature scaling is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). Run the following code to feature scale your input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "by0c0S7s0rQY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_train)  \n",
    "x_train = scaler.transform(x_train) \n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxX0ugDuNR8o"
   },
   "source": [
    "Check that the shape of your data looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tJHqw2M0rQf"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90SIHxqzN3Ht"
   },
   "source": [
    "Train a classifier of your choice. Then report results:\n",
    "* Display the confusion matrix over the test set in absolute numbers.\n",
    "    * These numbers reflect number of true positives, true negatives, false positives and false negatives.\n",
    "* Display a normalized confusion matrix over the test set, so [sensitivity and specificity](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) can be read from the diagonal (off-diagonal will contain type I and type II error rates).\n",
    "    * Note that sensitivity is recall for the positive class (1), whereas specificity is recall for the negative class (0).\n",
    "* State **in free-text** the sensitivity and specificity of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIg8WIm3NiKN"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBkWn4WXA-QS"
   },
   "source": [
    "*Your explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP8IaWa9A-QS"
   },
   "source": [
    "## Part 5: Prediction with less leakage (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKIGA3BOA-QS"
   },
   "source": [
    "From Wikipedia, [data leakage](https://en.wikipedia.org/wiki/Leakage_(machine_learning)) is the use of information in the model training process which would not be expected to be available at prediction time, causing the predictive scores (metrics) to overestimate the model's utility when run in a production environment.\n",
    "\n",
    "Feature or column-wise leakage is caused by the inclusion of columns which are one of the following: a duplicate label, a proxy for the label, or the label itself\n",
    "\n",
    "Considering we're doing binary classification of whether a movie is science fiction, identify the most prominent cause of feature leakage among the features added during Exercise 3. \n",
    "\n",
    "1) **Argue** for your choice, 2) train a classifier not subject to this feature leakage (it's OK to create a new train/test split) and 3) **report the results** as you did in Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb7FTGgTA-QS"
   },
   "source": [
    "*Your explanation here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T14:01:15.648444Z",
     "start_time": "2021-09-27T14:01:15.643363Z"
    },
    "id": "9CzDjF_pA-QS"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc4EOB-gb5pp"
   },
   "source": [
    "# Exercise 4: Basic movie recommendation system (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PqirpLgVdN0"
   },
   "source": [
    "In this exercise, you'll build a simple movie recommendation system.  The system will take a movie as input and recommend a list of similar movies. In order to recommend similar movies, you will use the correlation between the ratings of movies as a similarity metric. We'll use Pearson's correlation. \n",
    " \n",
    "The data for this exercise is available in the following URLs. It contains basic info about movies, as well as ratings provided by several users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T14:49:08.552678Z",
     "start_time": "2021-09-27T14:49:08.547286Z"
    },
    "id": "HOHERjo8cLQo"
   },
   "outputs": [],
   "source": [
    "url1 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/ratings.csv'\n",
    "url2 = 'http://courses.compute.dtu.dk/02807/2021/projects/project1/movies.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOXKd22xXgo2"
   },
   "source": [
    "## Part 1: Preparing the ratings data (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Isn8M65HXi3i"
   },
   "source": [
    "Read the data from these two URLs, and create a single dataframe from them, with the following columns:\n",
    "\n",
    "| userId | movieId | rating | timestamp | title | genres |\n",
    "|--------|---------|--------|-----------|-------|--------|\n",
    "|        |         |        |           |       |        |\n",
    "\n",
    "Call the dataframe `movie_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwhdEsGUn1zz"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFGc9VSzadHi"
   },
   "source": [
    "To find the correlation between the ratings of movies, create a dataframe where each column is a movie name and each row contains the rating assigned by a specific user to that movie. \n",
    "\n",
    "You'll notice that this dataframe has many NaN values, since each movie is not rated by every user. Call the dataframe `user_ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTrrVPsrfn1Q"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy61Luqyu2Te"
   },
   "source": [
    "## Part 2: Finding the most similar movies (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7FBDshDd1j7"
   },
   "source": [
    "Each column contains all the user ratings for a particular movie. Let's take the user ratings for the movie Toy Story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e-9WXAro_4-"
   },
   "outputs": [],
   "source": [
    "toystory_ratings = user_ratings['Toy Story (1995)']\n",
    "toystory_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fljIQkJmpCJD"
   },
   "source": [
    "Next, find the correlation between the user ratings for Toy Story and the user ratings of all other movies. \n",
    " \n",
    "More specifically, create a dataframe that contains two columns, called `title` and `Correlation`. Each row should contain a movie title $x$, followed by the pairwise correlation between the column of ratings for Toy Story and the column of ratings for $x$.  Drop any rows with null values, and display the resulting dataframe.\n",
    " \n",
    "Use built-in functions to compute correlations and avoid explicit loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yuX1U0Xh0nk"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aji7cUw-r-JG"
   },
   "source": [
    "Sort the movies by descending order of correlation to find out highly correlated movies at the top. Display the 5 most highly correlated movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU0Zm9fjg4BD"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrvD_u63sVdD"
   },
   "source": [
    "If you computed correlations correctly, you will find that the recommended movies are not very well known. We can generate more popular recommendations by finding highly correlated movies that have a sensible number of ratings. \n",
    " \n",
    "Add a column to your correlation table, called `rating_counts`, which stores the number of ratings received by each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvMKUmBFg-Ow"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_20nfFvt-7y"
   },
   "source": [
    "Now find the 5 movies with the highest correlation with Toy Story, which have strictly more than 100 ratings. Display the result below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvE3c2lMhHNz"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7sVQeTkLYI2b"
   ],
   "name": "02807_Project_1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c66c630706217e3a010f48b864026cc87c4c3bb876d794d9e6fd30ae5531d371"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "362px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
